# job-description-chat-bot

Chat with your documents using the power of **Llama3-8B** and **Groq**! 
This Streamlit app lets you upload PDFs, converts them into embeddings with HuggingFace, and retrieves smart, contextual answers at lightning speed.

##  Features

- Upload and process PDF job descriptions
- Smart document embedding using HuggingFace
- Fast similarity search with FAISS
- Intelligent answers powered by Llama3-8B and Groq
- User-friendly Streamlit interface

##  Requirements

- Python 3.x
- Streamlit â€“ for the web UI
- Langchain - to chain together the retrieval and LLM calls 
- HuggingFace Embeddings â€“ for document vectorization
- FAISS â€“ for efficient similarity search
- Groq + Llama3-8B â€“ for fast, powerful natural language answers
- PyPDFDirectoryLoader â€“ to load PDFs from a directory

## Getting Started

### Environment Setup
Before running the app, make sure to set up your environment variables:
1. Create a `.env` file in the root directory
2. Add your GROQ_API_KEY:
   ```bash
   GROQ_API_KEY=<your_groq_api_key>
   ```

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/akhilaraop/job-description-chat.git
   cd job-description-chat-bot
   ```
2. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the Streamlit app:
   ```bash
   streamlit run main.py
   ```
4. Open the app in your browser (usually at http://localhost:8501)

## Testing

The project includes unit tests to ensure functionality. To run the tests:

1. Make sure you're in the virtual environment:
   ```bash
   source venv310/bin/activate
   ```

2. Run all tests:
   ```bash
   python -m pytest tests/
   ```

3. For verbose output:
   ```bash
   python -m pytest tests/ -v
   ```

4. To run a specific test file:
   ```bash
   python -m pytest tests/test_app.py
   ```

The test suite includes:
- App initialization tests
- Document processing tests
- Query handling tests
- Context retrieval tests

## ğŸ” Functionality

- **Document Ingestion**: Upload your PDF job descriptions to be processed by the system
- **Smart Embedding**: Documents are automatically processed and embedded using state-of-the-art HuggingFace models
- **Efficient Retrieval**: FAISS vector database enables lightning-fast similarity search
- **Intelligent Q&A**: Ask questions about your job descriptions and get contextual answers powered by Llama3-8B
- **Real-time Processing**: Get instant responses with Groq's high-performance infrastructure

## ğŸ” How It Works (Data Flow)

```text
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Start Streamlit App    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Display UI Title & Prompt   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  [Button Click] "Document Embeddings"â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Load PDFs from "./job_descriptions" folder â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ Split documents into chunks         â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ Create embeddings using HuggingFace â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ Store in FAISS vector DB            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ [User Input] Enter a question       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Retrieve relevant chunks from FAISS â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ Pass context + question to Llama3   â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ Generate answer via ChatGroq        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Display answer + response time      â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚ Show documents used (if expanded)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Architecture

### Class Diagram
See [class_diagram.md](assets/class_diagram.md) for the detailed class diagram of the application.

### Information Flow

1. **Application Initialization**:
   - `main.py` creates an instance of `RAGApp`
   - `RAGApp` initializes `DocumentProcessor` and `RAGModel`
   - Environment variables are loaded and validated

2. **Document Processing Flow**:
   ```
   User clicks "Document Embeddings" 
   â†’ RAGApp.prepare_vectorstore() 
   â†’ DocumentProcessor.load_and_embed() 
   â†’ Documents are loaded, split, and embedded 
   â†’ FAISS vector store is created and cached
   ```

3. **Query Processing Flow**:
   ```
   User enters question 
   â†’ RAGApp.handle_user_input() 
   â†’ RAGApp.query_documents() 
   â†’ RAGModel.get_response() 
   â†’ Retrieval chain processes query 
   â†’ Response is displayed with context
   ```

## Components

### RAGApp
The main application class that handles the Streamlit UI and coordinates between document processing and query handling.

### DocumentProcessor
Responsible for:
- Loading PDF documents from the specified directory
- Splitting documents into chunks
- Creating embeddings using HuggingFace's all-MiniLM-L6-v2 model
- Building and returning a FAISS vector store

### RAGModel
Handles the interaction with the Llama3 8B model through Groq's API:
- Initializes the language model with the Groq API key
- Creates a prompt template for context-aware responses
- Processes queries using a retrieval chain

## Dependencies

- Python 3.10+
- Streamlit
- LangChain
- FAISS
- HuggingFace Transformers
- Groq API

## Setup

1. Clone the repository
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Set up your environment variables:
   ```bash
   export GROQ_API_KEY="your-api-key"
   ```
4. Place your PDF documents in the `job_descriptions` directory
5. Run the application:
   ```bash
   python main.py
   ```

## Usage

1. Click the "Document Embeddings" button to process your documents
2. Enter your question in the text input field
3. View the response and relevant document context

## Features

- PDF document processing and embedding
- Context-aware question answering
- Similarity search results display
- Streamlit-based user interface
- Performance metrics display
